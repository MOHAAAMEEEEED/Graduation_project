{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MOHAAAMEEEEED/Graduation_project/blob/main/audio_%26_keyword_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ipXlrai_oPFs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import whisper\n",
    "import logging\n",
    "from typing import Optional, Dict, Union\n",
    "from pathlib import Path\n",
    "\n",
    "class WhisperTranscriber:\n",
    "    \"\"\"\n",
    "    A class to handle audio/video transcription using OpenAI's Whisper model.\n",
    "    Supports multiple input formats and handles conversion to WAV using FFmpeg.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the transcriber with the 'base' Whisper model.\n",
    "        \"\"\"\n",
    "        self.setup_logging()\n",
    "        self.model = whisper.load_model(\"base\")\n",
    "        self.language = \"en\"\n",
    "\n",
    "    def setup_logging(self) -> None:\n",
    "        \"\"\"Configure logging for the transcriber.\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,         #  Set the logging level to INFO to capture informational messages and above\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)       # Create a logger instance associated with the current module's name, allowing other methods to log messages\n",
    "\n",
    "    def convert_to_wav(self, input_file: Union[str, Path], output_dir: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"#\n",
    "        Convert input audio/video file to WAV format using FFmpeg.\n",
    "\n",
    "        Args:\n",
    "            input_file (Union[str, Path]): Path to input audio/video file\n",
    "            output_dir (Optional[str]): Directory for output WAV file\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: Path to output WAV file if successful, None otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            input_path = Path(input_file)\n",
    "            if not input_path.exists():\n",
    "                self.logger.error(f\"Input file not found: {input_file}\")\n",
    "                return None\n",
    "\n",
    "            # Determine output path\n",
    "            if output_dir:\n",
    "                output_path = Path(output_dir) / f\"{input_path.stem}.wav\"\n",
    "            else:\n",
    "                output_path = input_path.with_suffix('.wav')\n",
    "\n",
    "            # Create output directory if it doesn't exist\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # FFmpeg command for conversion\n",
    "            command = [\n",
    "                'ffmpeg',\n",
    "                '-i', str(input_path),\n",
    "                '-ar', '16000',  # Sample rate 16kHz\n",
    "                '-ac', '1',      # Mono audio\n",
    "                '-c:a', 'pcm_s16le',  # 16-bit PCM encoding\n",
    "                str(output_path),\n",
    "                '-y'  # Overwrite output file if exists\n",
    "            ]\n",
    "\n",
    "            self.logger.info(f\"Converting {input_path} to WAV format\")\n",
    "            result = subprocess.run(\n",
    "                command,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True\n",
    "            )\n",
    "\n",
    "            if result.returncode != 0:\n",
    "                self.logger.error(f\"FFmpeg conversion failed: {result.stderr}\")\n",
    "                return None\n",
    "\n",
    "            self.logger.info(\"Conversion successful\")\n",
    "            return str(output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during conversion: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def transcribe(self,\n",
    "                  input_file: Union[str, Path],\n",
    "                  output_dir: Optional[str] = None,\n",
    "                  cleanup: bool = True) -> Dict:\n",
    "        \"\"\"\n",
    "        Transcribe audio/video file using Whisper.\n",
    "\n",
    "        Args:\n",
    "            input_file (Union[str, Path]): Path to input audio/video file\n",
    "            output_dir (Optional[str]): Directory for temporary WAV file\n",
    "            cleanup (bool): Whether to delete temporary WAV file after transcription\n",
    "\n",
    "        Returns:\n",
    "            Dict: Transcription result containing text and other metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert to WAV if input is not already WAV\n",
    "            input_path = Path(input_file)\n",
    "            if input_path.suffix.lower() != '.wav':\n",
    "                self.logger.info(\"Converting input file to WAV format\")\n",
    "                wav_file = self.convert_to_wav(input_file, output_dir)\n",
    "                if not wav_file:\n",
    "                    raise RuntimeError(\"Failed to convert input file to WAV format\")\n",
    "            else:\n",
    "                wav_file = str(input_path)\n",
    "\n",
    "            # Perform transcription\n",
    "            self.logger.info(\"Starting transcription\")\n",
    "            result = self.model.transcribe(wav_file, language=self.language)\n",
    "            self.logger.info(\"Transcription completed successfully\")\n",
    "\n",
    "            # Cleanup temporary WAV file if requested\n",
    "            if cleanup and input_path.suffix.lower() != '.wav':\n",
    "                try:\n",
    "                    os.remove(wav_file)\n",
    "                    self.logger.info(f\"Cleaned up temporary WAV file: {wav_file}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Failed to cleanup temporary file: {str(e)}\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Transcription failed: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cTrOIhSpRxz",
    "outputId": "dd7a9389-3bee-4960-993d-9146739142f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed Walid\\AppData\\Roaming\\Python\\Python39\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "2024-11-24 16:12:16,527 - INFO - Converting input file to WAV format\n",
      "2024-11-24 16:12:16,527 - INFO - Converting C:\\Users\\Mohamed Walid\\OneDrive\\Desktop\\1732456960148c78vzx5e-voicemaker.in-speech.mp3 to WAV format\n",
      "2024-11-24 16:12:16,859 - INFO - Conversion successful\n",
      "2024-11-24 16:12:16,859 - INFO - Starting transcription\n",
      "2024-11-24 16:12:19,837 - INFO - Transcription completed successfully\n",
      "2024-11-24 16:12:19,839 - INFO - Cleaned up temporary WAV file: C:\\Users\\Mohamed Walid\\OneDrive\\Desktop\\1732456960148c78vzx5e-voicemaker.in-speech.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  Many software engineers work as employees or contractors. Software engineers work with businesses, government agencies, civilian or military, and non-profit organizations. Some software engineers work for themselves as freelancers. Some organization.\n"
     ]
    }
   ],
   "source": [
    "# Initialize transcriber\n",
    "transcriber = WhisperTranscriber()\n",
    "\n",
    "input_file = \"C:/Users/Mohamed Walid/OneDrive/Desktop/1732456960148c78vzx5e-voicemaker.in-speech.mp3\"\n",
    "try:\n",
    "    result = transcriber.transcribe(input_file)\n",
    "\n",
    "    # Store the transcribed text in a variable\n",
    "    transcribed_text = result['text']\n",
    "\n",
    "    # Print the transcribed text\n",
    "    print(f\"Transcription: {transcribed_text}\")\n",
    "\n",
    "    # You can now use transcribed_text for further processing\n",
    "    # For example, save to a file or use in other functions\n",
    "except Exception as e:\n",
    "    print(f\"Transcription failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niaX206YJp4y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIDF-M5sxoD0"
   },
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgybLuH5xmWB",
    "outputId": "389492d9-52ce-441d-8be7-3bc14f5914dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohamed\n",
      "[nltk_data]     Walid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohamed\n",
      "[nltk_data]     Walid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mohamed\n",
      "[nltk_data]     Walid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZnB0qQHx-Mx",
    "outputId": "a84be96d-3ebe-45bd-d7f3-83cafb0de50c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~ "
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "for char in string.punctuation:\n",
    "    print(char,end= \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0e3rJEz0WSA"
   },
   "source": [
    "#### Using `lemmatization` here in preprocessing as it reduces words to their base , considering the context and the actual meaning. which will be useful for `keyword extraction` as it help maintain the correct semantic meaning, improving the accuracy .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nl_9Ql5EyP9S"
   },
   "outputs": [],
   "source": [
    "translated_table = str.maketrans('', '', string.punctuation)\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(translated_table)\n",
    "\n",
    "    text = re.sub(r'\\d+', '', text)       # Remove numbers\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and lemmatize\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    #processed_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtHI239yzmk5",
    "outputId": "b69d6405-285e-439b-a139-7d8ec9110c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Text: many software engineer work employee contractor software engineer work business government agency civilian military nonprofit organization software engineer work freelancer organization\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = preprocess_text(transcribed_text)\n",
    "print(f\"Preprocessed Text: {preprocessed_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZS_NOqHO3FnF"
   },
   "source": [
    "#### extract important keywords from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2a_b7RP2bYO",
    "outputId": "1e47b747-72ac-45bf-b256-e5b81e2c3087"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 16:35:44,124 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-24 16:35:44,125 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant job keywords: ['employee contractor', 'software engineer', 'contractor software', 'contractor', 'freelancer organization', 'work freelancer', 'agency civilian', 'freelancer', 'engineer work']\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "import spacy\n",
    "\n",
    "\n",
    "# Load spaCy model for POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample preprocessed text, replace this with your actual preprocessed text\n",
    "text = preprocessed_text\n",
    "# Initialize KeyBERT model\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# Extract keywords with KeyBERT\n",
    "raw_keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=10)\n",
    "raw_keywords = [kw[0] for kw in raw_keywords]  # Keep only the keywords without scores\n",
    "\n",
    "# Filter keywords using spaCy for relevant parts of speech\n",
    "filtered_keywords = []\n",
    "for keyword in raw_keywords:\n",
    "    doc = nlp(keyword)\n",
    "    # Check if all tokens in the keyword are either NOUN or PROPN\n",
    "    if all(token.pos_ in {\"NOUN\", \"PROPN\"} for token in doc):\n",
    "        filtered_keywords.append(keyword)\n",
    "\n",
    "print(\"Relevant job keywords:\", filtered_keywords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bMG0XK9EVjM"
   },
   "source": [
    "#### Find synonyms of words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlAA-suoHjdk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['employee contractor',\n",
       " 'software engineer',\n",
       " 'contractor software',\n",
       " 'contractor',\n",
       " 'freelancer organization',\n",
       " 'work freelancer',\n",
       " 'agency civilian',\n",
       " 'freelancer',\n",
       " 'engineer work']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee contractor software engineer contractor software contractor freelancer organization work freelancer agency civilian freelancer engineer work"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fol=' '.join(filtered_keywords)\n",
    "#fol   \n",
    "doc=nlp(fol)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "# Function to fetch synonyms for a word using WordNet\n",
    "def get_synonyms(word):\n",
    "    \"\"\"Fetch a set of synonyms for a word using WordNet.\"\"\"\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "# Function to generate n-grams (1-gram and 2-gram) from the tokens\n",
    "def generate_ngrams(tokens, n=2):\n",
    "    \"\"\"Generate n-grams from the list of tokens.\"\"\"\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [' '.join(gram) for gram in n_grams]\n",
    "\n",
    "# Function to combine each word in the text with its synonyms\n",
    "def combine_with_synonyms(doc):\n",
    "    \"\"\"Combine each word in the text with its synonyms.\"\"\"\n",
    "    combined_dict = {}\n",
    "    for token in doc:\n",
    "        word = token.text.lower()  # Convert to lowercase for consistency\n",
    "        synonyms = get_synonyms(word)\n",
    "        combined_dict[word] = list(synonyms)  # Store as a list of synonyms\n",
    "    return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the synonyms for each token in the processed text\n",
    "result = combine_with_synonyms(doc)\n",
    "\n",
    "# Get tokens from doc\n",
    "tokens = [token.text.lower() for token in doc]\n",
    "\n",
    "# Generate unigrams (1-grams) and bigrams (2-grams)\n",
    "unigrams = generate_ngrams(tokens, n=1)\n",
    "bigrams = generate_ngrams(tokens, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams: ['employee', 'contractor', 'software', 'engineer', 'contractor', 'software', 'contractor', 'freelancer', 'organization', 'work', 'freelancer', 'agency', 'civilian', 'freelancer', 'engineer', 'work']\n",
      "Bigrams: ['employee contractor', 'contractor software', 'software engineer', 'engineer contractor', 'contractor software', 'software contractor', 'contractor freelancer', 'freelancer organization', 'organization work', 'work freelancer', 'freelancer agency', 'agency civilian', 'civilian freelancer', 'freelancer engineer', 'engineer work']\n",
      "Synonyms: {'employee': ['employee'], 'contractor': ['declarer', 'contractile_organ', 'contractor'], 'software': ['computer_software', 'software_package', 'software', 'package', 'software_system', 'software_program'], 'engineer': ['orchestrate', 'applied_scientist', 'organize', 'technologist', 'mastermind', 'engine_driver', 'engineer', 'locomotive_engineer', 'direct', 'railroad_engineer', 'organise'], 'freelancer': ['independent', 'free-lance', 'self-employed_person', 'self-employed', 'freelance', 'freelancer', 'free_lance', 'mercenary'], 'organization': ['organization', 'formation', 'constitution', 'administration', 'establishment', 'arrangement', 'governance', 'system', 'governing_body', 'organisation', 'brass'], 'work': ['work_on', 'form', 'study', 'play', 'wreak', 'process', 'body_of_work', 'function', 'go', 'lick', 'cultivate', 'crop', 'puzzle_out', 'put_to_work', 'oeuvre', 'mould', 'ferment', 'employment', 'operate', 'figure_out', 'mold', 'run', 'work', 'turn', 'make', 'piece_of_work', 'solve', 'bring', 'forge', 'do_work', 'exploit', 'make_for', 'workplace', 'work_out', 'act', 'knead', 'influence', 'exercise', 'sour', 'act_upon', 'shape'], 'agency': ['government_agency', 'way', 'bureau', 'delegacy', 'representation', 'office', 'authority', 'federal_agency', 'agency', 'means'], 'civilian': ['civilian']}\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Unigrams:\", unigrams)\n",
    "print(\"Bigrams:\", bigrams)\n",
    "\n",
    "# Print the synonyms\n",
    "print(\"Synonyms:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch synonyms for a word using WordNet\n",
    "def get_synonyms(word):\n",
    "    \"\"\"Fetch a set of synonyms for a word using WordNet.\"\"\"\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "# Function to generate n-grams (1-gram and 2-gram) from the tokens\n",
    "def generate_ngrams(tokens, n=2):\n",
    "    \"\"\"Generate n-grams from the list of tokens.\"\"\"\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [' '.join(gram) for gram in n_grams]\n",
    "\n",
    "# Function to combine each word or phrase (bigram) with its synonyms\n",
    "def combine_with_synonyms(doc, n=2):\n",
    "    \"\"\"Combine each word in the text with its synonyms (including bigrams).\"\"\"\n",
    "    combined_dict = {}\n",
    "    tokens = [token.text.lower() for token in doc]  # Get list of tokens from doc\n",
    "    n_grams = generate_ngrams(tokens, n)  # Generate n-grams (1 or 2)\n",
    "    \n",
    "    for gram in n_grams:\n",
    "        synonyms_for_bigram = set()\n",
    "        words_in_bigram = gram.split()  # Split bigram into individual words\n",
    "        \n",
    "        # Get synonyms for each word in the bigram\n",
    "        for word in words_in_bigram:\n",
    "            synonyms_for_bigram.update(get_synonyms(word))\n",
    "        \n",
    "        combined_dict[gram] = list(synonyms_for_bigram)  # Store the synonyms for the bigram\n",
    "    \n",
    "    return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'employee contractor': ['contractor', 'declarer', 'employee', 'contractile_organ'], 'contractor software': ['computer_software', 'software_package', 'software', 'contractor', 'package', 'software_system', 'software_program', 'declarer', 'contractile_organ'], 'software engineer': ['software', 'engine_driver', 'package', 'software_program', 'railroad_engineer', 'direct', 'organize', 'organise', 'computer_software', 'software_package', 'applied_scientist', 'technologist', 'mastermind', 'engineer', 'software_system', 'locomotive_engineer', 'orchestrate'], 'engineer contractor': ['orchestrate', 'applied_scientist', 'organize', 'contractor', 'technologist', 'mastermind', 'engine_driver', 'engineer', 'locomotive_engineer', 'declarer', 'contractile_organ', 'direct', 'railroad_engineer', 'organise'], 'software contractor': ['computer_software', 'software_package', 'software', 'contractor', 'package', 'software_system', 'software_program', 'declarer', 'contractile_organ'], 'contractor freelancer': ['independent', 'free-lance', 'self-employed_person', 'self-employed', 'contractor', 'freelance', 'declarer', 'freelancer', 'free_lance', 'contractile_organ', 'mercenary'], 'freelancer organization': ['organization', 'free-lance', 'self-employed_person', 'self-employed', 'formation', 'administration', 'establishment', 'governance', 'freelance', 'free_lance', 'brass', 'independent', 'constitution', 'arrangement', 'system', 'governing_body', 'freelancer', 'organisation', 'mercenary'], 'organization work': ['formation', 'administration', 'work_on', 'form', 'governance', 'study', 'act_upon', 'play', 'wreak', 'process', 'body_of_work', 'function', 'brass', 'go', 'lick', 'cultivate', 'crop', 'puzzle_out', 'put_to_work', 'arrangement', 'oeuvre', 'ferment', 'employment', 'operate', 'figure_out', 'governing_body', 'organisation', 'mold', 'run', 'work', 'turn', 'make', 'organization', 'piece_of_work', 'solve', 'bring', 'establishment', 'do_work', 'exploit', 'make_for', 'workplace', 'work_out', 'constitution', 'exercise', 'act', 'knead', 'influence', 'system', 'forge', 'sour', 'mould', 'shape'], 'work freelancer': ['work_on', 'form', 'study', 'play', 'wreak', 'process', 'body_of_work', 'function', 'go', 'lick', 'cultivate', 'crop', 'puzzle_out', 'put_to_work', 'oeuvre', 'mould', 'ferment', 'employment', 'operate', 'figure_out', 'freelancer', 'mold', 'run', 'work', 'turn', 'make', 'mercenary', 'piece_of_work', 'solve', 'free-lance', 'bring', 'self-employed_person', 'self-employed', 'freelance', 'forge', 'do_work', 'exploit', 'make_for', 'workplace', 'free_lance', 'work_out', 'independent', 'act', 'knead', 'influence', 'exercise', 'sour', 'act_upon', 'shape'], 'freelancer agency': ['agency', 'government_agency', 'way', 'independent', 'free-lance', 'self-employed_person', 'self-employed', 'bureau', 'authority', 'freelance', 'delegacy', 'representation', 'office', 'freelancer', 'federal_agency', 'free_lance', 'means', 'mercenary'], 'agency civilian': ['government_agency', 'way', 'civilian', 'bureau', 'delegacy', 'representation', 'office', 'authority', 'federal_agency', 'agency', 'means'], 'civilian freelancer': ['independent', 'free-lance', 'self-employed_person', 'self-employed', 'civilian', 'freelance', 'freelancer', 'free_lance', 'mercenary'], 'freelancer engineer': ['free-lance', 'self-employed_person', 'self-employed', 'engine_driver', 'freelance', 'railroad_engineer', 'direct', 'free_lance', 'organize', 'organise', 'independent', 'applied_scientist', 'technologist', 'mastermind', 'engineer', 'locomotive_engineer', 'freelancer', 'orchestrate', 'mercenary'], 'engineer work': ['work_on', 'form', 'study', 'act_upon', 'play', 'wreak', 'process', 'body_of_work', 'function', 'organize', 'go', 'lick', 'cultivate', 'applied_scientist', 'crop', 'puzzle_out', 'mastermind', 'put_to_work', 'oeuvre', 'engineer', 'ferment', 'employment', 'operate', 'figure_out', 'mold', 'run', 'work', 'orchestrate', 'railroad_engineer', 'turn', 'make', 'piece_of_work', 'solve', 'bring', 'engine_driver', 'do_work', 'exploit', 'make_for', 'workplace', 'direct', 'organise', 'work_out', 'exercise', 'technologist', 'locomotive_engineer', 'act', 'knead', 'influence', 'forge', 'sour', 'mould', 'shape']}\n"
     ]
    }
   ],
   "source": [
    "# Get the synonyms for each token or bigram in the processed text\n",
    "result = combine_with_synonyms(doc, n=2)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'employee contractor': {'declarer': 0.5217391304347826, 'contractile_organ': 0.26666666666666666}, 'contractor software': {'declarer': 0.5217391304347826, 'contractile_organ': 0.26666666666666666, 'computer_software': 1.0, 'software_package': 1.0, 'package': 0.3076923076923077, 'software_system': 1.0, 'software_program': 1.0}, 'software engineer': {'computer_software': 1.0, 'software_package': 1.0, 'package': 0.3076923076923077, 'software_system': 1.0, 'software_program': 1.0, 'orchestrate': 0.16666666666666666, 'applied_scientist': 0.75, 'organize': 0.2, 'technologist': 0.75, 'mastermind': 0.7058823529411765, 'engine_driver': 0.6, 'locomotive_engineer': 0.6, 'direct': 0.11764705882352941, 'railroad_engineer': 0.6, 'organise': 0.16666666666666666}, 'engineer contractor': {'orchestrate': 0.16666666666666666, 'applied_scientist': 0.75, 'organize': 0.2, 'technologist': 0.75, 'mastermind': 0.7058823529411765, 'engine_driver': 0.6, 'locomotive_engineer': 0.6, 'direct': 0.11764705882352941, 'railroad_engineer': 0.6, 'organise': 0.16666666666666666, 'declarer': 0.5217391304347826, 'contractile_organ': 0.26666666666666666}, 'software contractor': {'computer_software': 1.0, 'software_package': 1.0, 'package': 0.3076923076923077, 'software_system': 1.0, 'software_program': 1.0, 'declarer': 0.5217391304347826, 'contractile_organ': 0.26666666666666666}, 'contractor freelancer': {'declarer': 0.5217391304347826, 'contractile_organ': 0.26666666666666666, 'independent': 0.6666666666666666, 'free-lance': 1.0, 'self-employed_person': 1.0, 'self-employed': 0.2, 'freelance': 1.0, 'free_lance': 1.0, 'mercenary': 0.6666666666666666}, 'freelancer organization': {'independent': 0.6666666666666666, 'free-lance': 1.0, 'self-employed_person': 1.0, 'self-employed': 0.2, 'freelance': 1.0, 'free_lance': 1.0, 'mercenary': 0.6666666666666666, 'formation': 0.6, 'constitution': 0.2857142857142857, 'administration': 0.3076923076923077, 'establishment': 0.26666666666666666, 'arrangement': 0.2857142857142857, 'governance': 0.7272727272727273, 'system': 0.16666666666666666, 'governing_body': 0.7272727272727273, 'organisation': 0.7272727272727273, 'brass': 0.2857142857142857}, 'organization work': {'formation': 0.6, 'constitution': 0.2857142857142857, 'administration': 0.3076923076923077, 'establishment': 0.26666666666666666, 'arrangement': 0.2857142857142857, 'governance': 0.7272727272727273, 'system': 0.16666666666666666, 'governing_body': 0.7272727272727273, 'organisation': 0.7272727272727273, 'brass': 0.2857142857142857, 'work_on': 0.18181818181818182, 'form': 0.2857142857142857, 'study': 0.8235294117647058, 'play': 0.2857142857142857, 'wreak': 0.18181818181818182, 'process': 0.8571428571428571, 'body_of_work': 0.125, 'function': 0.3333333333333333, 'go': 0.25, 'lick': 0.16666666666666666, 'cultivate': 0.2, 'crop': 0.5, 'puzzle_out': 0.18181818181818182, 'put_to_work': 0.18181818181818182, 'oeuvre': 0.125, 'mould': 0.25, 'ferment': 0.2857142857142857, 'employment': 0.3333333333333333, 'operate': 0.15384615384615385, 'figure_out': 0.18181818181818182, 'mold': 0.3076923076923077, 'run': 0.5555555555555556, 'turn': 0.2857142857142857, 'make': 0.35294117647058826, 'piece_of_work': 0.13333333333333333, 'solve': 0.18181818181818182, 'bring': 0.16666666666666666, 'forge': 0.1111111111111111, 'do_work': 0.2, 'exploit': 0.6666666666666666, 'make_for': 0.18181818181818182, 'workplace': 0.14285714285714285, 'work_out': 0.16666666666666666, 'act': 0.26666666666666666, 'knead': 0.15384615384615385, 'influence': 0.3076923076923077, 'exercise': 0.8235294117647058, 'sour': 0.21052631578947367, 'act_upon': 0.16666666666666666, 'shape': 0.3076923076923077}, 'work freelancer': {'work_on': 0.18181818181818182, 'form': 0.2857142857142857, 'study': 0.8235294117647058, 'play': 0.2857142857142857, 'wreak': 0.18181818181818182, 'process': 0.8571428571428571, 'body_of_work': 0.125, 'function': 0.3333333333333333, 'go': 0.25, 'lick': 0.16666666666666666, 'cultivate': 0.2, 'crop': 0.5, 'puzzle_out': 0.18181818181818182, 'put_to_work': 0.18181818181818182, 'oeuvre': 0.125, 'mould': 0.25, 'ferment': 0.2857142857142857, 'employment': 0.3333333333333333, 'operate': 0.15384615384615385, 'figure_out': 0.18181818181818182, 'mold': 0.3076923076923077, 'run': 0.5555555555555556, 'turn': 0.2857142857142857, 'make': 0.35294117647058826, 'piece_of_work': 0.13333333333333333, 'solve': 0.18181818181818182, 'bring': 0.16666666666666666, 'forge': 0.1111111111111111, 'do_work': 0.2, 'exploit': 0.6666666666666666, 'make_for': 0.18181818181818182, 'workplace': 0.14285714285714285, 'work_out': 0.16666666666666666, 'act': 0.26666666666666666, 'knead': 0.15384615384615385, 'influence': 0.3076923076923077, 'exercise': 0.8235294117647058, 'sour': 0.21052631578947367, 'act_upon': 0.16666666666666666, 'shape': 0.3076923076923077, 'independent': 0.6666666666666666, 'free-lance': 1.0, 'self-employed_person': 1.0, 'self-employed': 0.2, 'freelance': 1.0, 'free_lance': 1.0, 'mercenary': 0.6666666666666666}, 'freelancer agency': {'independent': 0.6666666666666666, 'free-lance': 1.0, 'self-employed_person': 1.0, 'self-employed': 0.2, 'freelance': 1.0, 'free_lance': 1.0, 'mercenary': 0.6666666666666666, 'government_agency': 1.0, 'way': 0.3076923076923077, 'bureau': 1.0, 'delegacy': 0.3076923076923077, 'representation': 0.2857142857142857, 'office': 0.11764705882352941, 'authority': 0.26666666666666666, 'federal_agency': 1.0, 'means': 0.26666666666666666}, 'agency civilian': {'government_agency': 1.0, 'way': 0.3076923076923077, 'bureau': 1.0, 'delegacy': 0.3076923076923077, 'representation': 0.2857142857142857, 'office': 0.11764705882352941, 'authority': 0.26666666666666666, 'federal_agency': 1.0, 'means': 0.26666666666666666}, 'civilian freelancer': {'independent': 0.6666666666666666, 'free-lance': 1.0, 'self-employed_person': 1.0, 'self-employed': 0.2, 'freelance': 1.0, 'free_lance': 1.0, 'mercenary': 0.6666666666666666}, 'freelancer engineer': {'independent': 0.6666666666666666, 'free-lance': 1.0, 'self-employed_person': 1.0, 'self-employed': 0.2, 'freelance': 1.0, 'free_lance': 1.0, 'mercenary': 0.6666666666666666, 'orchestrate': 0.16666666666666666, 'applied_scientist': 0.75, 'organize': 0.2, 'technologist': 0.75, 'mastermind': 0.7058823529411765, 'engine_driver': 0.6, 'locomotive_engineer': 0.6, 'direct': 0.11764705882352941, 'railroad_engineer': 0.6, 'organise': 0.16666666666666666}, 'engineer work': {'orchestrate': 0.16666666666666666, 'applied_scientist': 0.75, 'organize': 0.2, 'technologist': 0.75, 'mastermind': 0.7058823529411765, 'engine_driver': 0.6, 'locomotive_engineer': 0.6, 'direct': 0.11764705882352941, 'railroad_engineer': 0.6, 'organise': 0.16666666666666666, 'work_on': 0.18181818181818182, 'form': 0.2857142857142857, 'study': 0.8235294117647058, 'play': 0.2857142857142857, 'wreak': 0.18181818181818182, 'process': 0.8571428571428571, 'body_of_work': 0.125, 'function': 0.3333333333333333, 'go': 0.25, 'lick': 0.16666666666666666, 'cultivate': 0.2, 'crop': 0.5, 'puzzle_out': 0.18181818181818182, 'put_to_work': 0.18181818181818182, 'oeuvre': 0.125, 'mould': 0.25, 'ferment': 0.2857142857142857, 'employment': 0.3333333333333333, 'operate': 0.15384615384615385, 'figure_out': 0.18181818181818182, 'mold': 0.3076923076923077, 'run': 0.5555555555555556, 'turn': 0.2857142857142857, 'make': 0.35294117647058826, 'piece_of_work': 0.13333333333333333, 'solve': 0.18181818181818182, 'bring': 0.16666666666666666, 'forge': 0.1111111111111111, 'do_work': 0.2, 'exploit': 0.6666666666666666, 'make_for': 0.18181818181818182, 'workplace': 0.14285714285714285, 'work_out': 0.16666666666666666, 'act': 0.26666666666666666, 'knead': 0.15384615384615385, 'influence': 0.3076923076923077, 'exercise': 0.8235294117647058, 'sour': 0.21052631578947367, 'act_upon': 0.16666666666666666, 'shape': 0.3076923076923077}}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Function to calculate similarity between words using Wu-Palmer Similarity\n",
    "def get_similarity(word1, word2):\n",
    "    \"\"\"Calculate the similarity between two words using WordNet's Wu-Palmer similarity.\"\"\"\n",
    "    syn1 = wordnet.synsets(word1)\n",
    "    syn2 = wordnet.synsets(word2)\n",
    "    \n",
    "    if syn1 and syn2:\n",
    "        # Calculate similarity between the first synsets of both words\n",
    "        return syn1[0].wup_similarity(syn2[0])  # Wu-Palmer similarity (range: 0 to 1)\n",
    "    return 0  # Return 0 if no similarity found\n",
    "\n",
    "# Function to combine each bigram with its synonyms and similarity\n",
    "def combine_with_synonyms_and_similarity(doc, n=2):\n",
    "    \"\"\"Combine each bigram in the text with its synonyms and calculate similarity.\"\"\"\n",
    "    combined_dict = {}\n",
    "    tokens = [token.text.lower() for token in doc]  # Tokenize and lowercase\n",
    "    n_grams = generate_ngrams(tokens, n)  # Generate n-grams\n",
    "    \n",
    "    for gram in n_grams:\n",
    "        synonyms_with_scores = {}\n",
    "        words_in_bigram = gram.split()  # Split bigram into individual words\n",
    "        \n",
    "        for word in words_in_bigram:\n",
    "            synonyms = get_synonyms(word)  # Get synonyms for the word\n",
    "            \n",
    "            for synonym in synonyms:\n",
    "                if word != synonym:  # Avoid self-similarity\n",
    "                    similarity_score = get_similarity(word, synonym)\n",
    "                    synonyms_with_scores[synonym] = similarity_score\n",
    "        \n",
    "        combined_dict[gram] = synonyms_with_scores  # Store the bigram with synonyms and scores\n",
    "    \n",
    "    return combined_dict\n",
    "\n",
    "# Example Usage\n",
    "result = combine_with_synonyms_and_similarity(doc, n=2)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMjZQNwPW+lzsguscCZ1Pcr",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
